Setting up training components...
Loading pretrained weights from /kaggle/input/cub-200-2011/ViT-B_16.npz
✓ Mixed precision training enabled (FP16)
✓ Gradient checkpointing enabled (trades compute for memory)
Model initialized with 93.65M parameters
CUB Dataset: 5994 train samples loaded
CUB Dataset: 5794 test samples loaded
Starting training for 100 epochs
Training samples: 5994
Validation samples: 5794
Physical batch size: 4
Gradient accumulation steps: 4
Effective batch size: 16
Epoch 1: 100%|##########| 1498/1498 [33:02<00:00,  1.32s/it, L=7.981, SA=0.01, GL=0.01, PW=0.01, w1=0.0, w2=0.0, w3=0.0]

================================================================================
EPOCH 1 SUMMARY
================================================================================
Learning Rate: 0.000016

Loss Breakdown:
  Total Loss:    7.9802
  SA Loss:       5.3423
  GLCA Loss:     5.3106
  PWCA Loss:     5.3449

Accuracy:
  SA Acc:        0.0067
  GLCA Acc:      0.0103
  PWCA Acc:      0.0060

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0029
  w2 (GLCA):     0.0029
  w3 (PWCA):     0.0029

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9971
  Weight GLCA:   0.9971
  Weight PWCA:   0.9971

⚠️  WARNING: SA accuracy is very low (0.67%)!
================================================================================
Epoch 2: 100%|##########| 1498/1498 [33:01<00:00,  1.32s/it, L=7.717, SA=0.02, GL=0.03, PW=0.01, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 2 SUMMARY
================================================================================
Learning Rate: 0.000016

Loss Breakdown:
  Total Loss:    7.7164
  SA Loss:       5.1366
  GLCA Loss:     5.1087
  PWCA Loss:     5.2963

Accuracy:
  SA Acc:        0.0245
  GLCA Acc:      0.0337
  PWCA Acc:      0.0093

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0087
  w2 (GLCA):     0.0087
  w3 (PWCA):     0.0088

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9913
  Weight GLCA:   0.9913
  Weight PWCA:   0.9912

⚠️  WARNING: SA accuracy is very low (2.45%)!
================================================================================
Epoch 3: 100%|##########| 1498/1498 [33:01<00:00,  1.32s/it, L=7.548, SA=0.06, GL=0.07, PW=0.01, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 3 SUMMARY
================================================================================
Learning Rate: 0.000016

Loss Breakdown:
  Total Loss:    7.5475
  SA Loss:       5.0113
  GLCA Loss:     4.9944
  PWCA Loss:     5.2666

Accuracy:
  SA Acc:        0.0589
  GLCA Acc:      0.0676
  PWCA Acc:      0.0107

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0145
  w2 (GLCA):     0.0145
  w3 (PWCA):     0.0148

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9856
  Weight GLCA:   0.9856
  Weight PWCA:   0.9854

⚠️  WARNING: SA accuracy is very low (5.89%)!
================================================================================
Epoch 4: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.459, SA=0.08, GL=0.08, PW=0.01, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 4 SUMMARY
================================================================================
Learning Rate: 0.000016

Loss Breakdown:
  Total Loss:    7.4591
  SA Loss:       4.9672
  GLCA Loss:     4.9608
  PWCA Loss:     5.2355

Accuracy:
  SA Acc:        0.0751
  GLCA Acc:      0.0811
  PWCA Acc:      0.0130

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0203
  w2 (GLCA):     0.0203
  w3 (PWCA):     0.0207

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9799
  Weight GLCA:   0.9799
  Weight PWCA:   0.9795

⚠️  WARNING: SA accuracy is very low (7.51%)!
================================================================================
Epoch 5: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.424, SA=0.07, GL=0.07, PW=0.02, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 5 SUMMARY
================================================================================
Learning Rate: 0.000016

Loss Breakdown:
  Total Loss:    7.4242
  SA Loss:       4.9735
  GLCA Loss:     4.9790
  PWCA Loss:     5.2101

Accuracy:
  SA Acc:        0.0676
  GLCA Acc:      0.0734
  PWCA Acc:      0.0155

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0261
  w2 (GLCA):     0.0261
  w3 (PWCA):     0.0266

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9743
  Weight GLCA:   0.9742
  Weight PWCA:   0.9738

⚠️  WARNING: SA accuracy is very low (6.76%)!
================================================================================
Evaluating val: 100%|###########################################| 1449/1449 [03:21<00:00,  7.20it/s]


Epoch 5/100
Train Loss: 7.4242
Val Top-1 Acc: 15.38% (Best: 15.38% @ epoch 5)
Val Top-5 Acc: 40.04%
New best model saved with metric: 15.3780
Epoch 6: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.426, SA=0.06, GL=0.06, PW=0.01, w1=0.0, w2=0.0, w3=0.0]

================================================================================
EPOCH 6 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4259
  SA Loss:       5.0023
  GLCA Loss:     5.0212
  PWCA Loss:     5.2131

Accuracy:
  SA Acc:        0.0554
  GLCA Acc:      0.0581
  PWCA Acc:      0.0139

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0319
  w2 (GLCA):     0.0319
  w3 (PWCA):     0.0324

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9686
  Weight GLCA:   0.9686
  Weight PWCA:   0.9682

⚠️  WARNING: SA accuracy is very low (5.54%)!
================================================================================
Epoch 7: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.440, SA=0.04, GL=0.04, PW=0.02, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 7 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4405
  SA Loss:       5.0478
  GLCA Loss:     5.0706
  PWCA Loss:     5.2190

Accuracy:
  SA Acc:        0.0369
  GLCA Acc:      0.0394
  PWCA Acc:      0.0162

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0377
  w2 (GLCA):     0.0378
  w3 (PWCA):     0.0381

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9630
  Weight GLCA:   0.9629
  Weight PWCA:   0.9626

⚠️  WARNING: SA accuracy is very low (3.69%)!
================================================================================
Epoch 8: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.444, SA=0.03, GL=0.03, PW=0.01, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 8 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4442
  SA Loss:       5.0865
  GLCA Loss:     5.1043
  PWCA Loss:     5.2254

Accuracy:
  SA Acc:        0.0277
  GLCA Acc:      0.0289
  PWCA Acc:      0.0115

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0435
  w2 (GLCA):     0.0436
  w3 (PWCA):     0.0439

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9574
  Weight GLCA:   0.9573
  Weight PWCA:   0.9571

⚠️  WARNING: SA accuracy is very low (2.77%)!
================================================================================
Epoch 9: 100%|##########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.443, SA=0.02, GL=0.02, PW=0.01, w1=0.0, w2=0.0, w3=0.0]


================================================================================
EPOCH 9 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4438
  SA Loss:       5.1153
  GLCA Loss:     5.1308
  PWCA Loss:     5.2403

Accuracy:
  SA Acc:        0.0227
  GLCA Acc:      0.0219
  PWCA Acc:      0.0120

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0493
  w2 (GLCA):     0.0494
  w3 (PWCA):     0.0496

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9519
  Weight GLCA:   0.9518
  Weight PWCA:   0.9516

⚠️  WARNING: SA accuracy is very low (2.27%)!
================================================================================
Epoch 10: 100%|#########| 1498/1498 [33:01<00:00,  1.32s/it, L=7.443, SA=0.02, GL=0.02, PW=0.01, w1=0.1, w2=0.1, w3=0.1]


================================================================================
EPOCH 10 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4431
  SA Loss:       5.1481
  GLCA Loss:     5.1586
  PWCA Loss:     5.2491

Accuracy:
  SA Acc:        0.0152
  GLCA Acc:      0.0167
  PWCA Acc:      0.0092

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0550
  w2 (GLCA):     0.0552
  w3 (PWCA):     0.0553

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9464
  Weight GLCA:   0.9463
  Weight PWCA:   0.9462

⚠️  WARNING: SA accuracy is very low (1.52%)!
================================================================================
Evaluating val: 100%|###########################################| 1449/1449 [03:21<00:00,  7.20it/s]


Epoch 10/100
Train Loss: 7.4431
Val Top-1 Acc: 1.86% (Best: 15.38% @ epoch 5)
Val Top-5 Acc: 7.84%
Epoch 11: 100%|#########| 1498/1498 [33:01<00:00,  1.32s/it, L=7.434, SA=0.01, GL=0.01, PW=0.01, w1=0.1, w2=0.1, w3=0.1]

================================================================================
EPOCH 11 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4345
  SA Loss:       5.1700
  GLCA Loss:     5.1776
  PWCA Loss:     5.2608

Accuracy:
  SA Acc:        0.0147
  GLCA Acc:      0.0135
  PWCA Acc:      0.0060

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0608
  w2 (GLCA):     0.0609
  w3 (PWCA):     0.0610

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9410
  Weight GLCA:   0.9409
  Weight PWCA:   0.9408

⚠️  WARNING: SA accuracy is very low (1.47%)!
================================================================================
Epoch 12: 100%|#########| 1498/1498 [33:01<00:00,  1.32s/it, L=7.412, SA=0.01, GL=0.01, PW=0.01, w1=0.1, w2=0.1, w3=0.1]


================================================================================
EPOCH 12 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.4124
  SA Loss:       5.1831
  GLCA Loss:     5.1877
  PWCA Loss:     5.2611

Accuracy:
  SA Acc:        0.0139
  GLCA Acc:      0.0135
  PWCA Acc:      0.0067

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0665
  w2 (GLCA):     0.0666
  w3 (PWCA):     0.0666

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9357
  Weight GLCA:   0.9356
  Weight PWCA:   0.9355

⚠️  WARNING: SA accuracy is very low (1.39%)!
================================================================================
Epoch 13: 100%|#########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.383, SA=0.01, GL=0.01, PW=0.01, w1=0.1, w2=0.1, w3=0.1]


================================================================================
EPOCH 13 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.3831
  SA Loss:       5.1877
  GLCA Loss:     5.1911
  PWCA Loss:     5.2607

Accuracy:
  SA Acc:        0.0093
  GLCA Acc:      0.0097
  PWCA Acc:      0.0062

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0722
  w2 (GLCA):     0.0723
  w3 (PWCA):     0.0723

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9304
  Weight GLCA:   0.9303
  Weight PWCA:   0.9303

⚠️  WARNING: SA accuracy is very low (0.93%)!
================================================================================
Epoch 14: 100%|#########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.355, SA=0.01, GL=0.01, PW=0.01, w1=0.1, w2=0.1, w3=0.1]


================================================================================
EPOCH 14 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.3544
  SA Loss:       5.1919
  GLCA Loss:     5.1968
  PWCA Loss:     5.2588

Accuracy:
  SA Acc:        0.0107
  GLCA Acc:      0.0113
  PWCA Acc:      0.0080

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0778
  w2 (GLCA):     0.0779
  w3 (PWCA):     0.0779

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9251
  Weight GLCA:   0.9250
  Weight PWCA:   0.9251

⚠️  WARNING: SA accuracy is very low (1.07%)!
================================================================================
Epoch 15: 100%|#########| 1498/1498 [33:00<00:00,  1.32s/it, L=7.322, SA=0.01, GL=0.01, PW=0.01, w1=0.1, w2=0.1, w3=0.1]


================================================================================
EPOCH 15 SUMMARY
================================================================================
Learning Rate: 0.000015

Loss Breakdown:
  Total Loss:    7.3224
  SA Loss:       5.1918
  GLCA Loss:     5.1982
  PWCA Loss:     5.2572

Accuracy:
  SA Acc:        0.0105
  GLCA Acc:      0.0112
  PWCA Acc:      0.0067

Uncertainty Weights (raw w_i):
  w1 (SA):       0.0834
  w2 (GLCA):     0.0835
  w3 (PWCA):     0.0834

Effective Loss Weights (1/exp(w_i)):
  Weight SA:     0.9200
  Weight GLCA:   0.9199
  Weight PWCA:   0.9200

⚠️  WARNING: SA accuracy is very low (1.05%)!
================================================================================
Evaluating val: 100%|###########################################| 1449/1449 [03:21<00:00,  7.20it/s]


Epoch 15/100
Train Loss: 7.3224
Val Top-1 Acc: 1.17% (Best: 15.38% @ epoch 5)
Val Top-5 Acc: 5.70%
Epoch 16:   0%|                                                                                | 0/1498 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/kaggle/working/clau_dual_cross_attention_learning/train.py", line 1093, in <module>
    main()
  File "/kaggle/working/clau_dual_cross_attention_learning/train.py", line 1085, in main
    trainer.train()
  File "/kaggle/working/clau_dual_cross_attention_learning/train.py", line 823, in train
    train_metrics = self.train_epoch(model, train_loader, criterion, optimizer, epoch, scheduler)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/kaggle/working/clau_dual_cross_attention_learning/train.py", line 514, in train_epoch
    self.scaler.scale(total_loss).backward()
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 225.12 MiB is free. Process 2673 has 15.67 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)